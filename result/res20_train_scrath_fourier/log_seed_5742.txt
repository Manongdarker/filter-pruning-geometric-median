save path : ./result/res20_train_scrath_fourier
{'arch': 'resnet20', 'batch_size': 128, 'data_path': '.\\data\\cifar10', 'dataset': 'cifar10', 'decay': 0.0005, 'dist_type': 'l2', 'epoch_prune': 1, 'epochs': 200, 'evaluate': False, 'gammas': [0.2, 0.2, 0.2], 'layer_begin': 0, 'layer_end': 54, 'layer_inter': 3, 'learning_rate': 0.1, 'manualSeed': 5742, 'momentum': 0.9, 'ngpu': 1, 'pretrain_path': '', 'print_freq': 200, 'rate_dist': 0.4, 'rate_norm': 1.0, 'resume': '', 'save_path': './result/res20_train_scrath_fourier', 'schedule': [60, 120, 160], 'start_epoch': 0, 'use_cuda': True, 'use_pretrain': False, 'use_state_dict': False, 'workers': 0}
Random Seed: 5742
python version : 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]
torch  version : 1.10.0
cudnn  version : 7605
Norm Pruning Rate: 1.0
Distance Pruning Rate: 0.4
Layer Begin: 0
Layer End: 54
Layer Inter: 3
Epoch prune: 1
use pretrain: False
Pretrain path: 
Dist type: l2
=> creating model 'resnet20'
=> network :
 CifarResNet(
  (conv_1_3x3): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (stage_1): Sequential(
    (0): ResNetBasicblock(
      (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ResNetBasicblock(
      (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_2): Sequential(
    (0): ResNetBasicblock(
      (conv_a): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_3): Sequential(
    (0): ResNetBasicblock(
      (conv_a): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (classifier): Linear(in_features=64, out_features=10, bias=True)
)
=> do not use any checkpoint for resnet20 model
  **Test** Prec@1 10.000 Prec@5 51.180 Error@1 90.000
  **Test** Prec@1 9.960 Prec@5 50.040 Error@1 90.040

==>>[2021-11-17 14:08:26] [Epoch=000/200] [Need: 00:00:00] [learning_rate=0.1000] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/391]   Time 0.140 (0.140)   Data 0.038 (0.038)   Loss 3.2105 (3.2105)   Prec@1 8.594 (8.594)   Prec@5 50.781 (50.781)   [2021-11-17 14:08:26]
  Epoch: [000][200/391]   Time 0.054 (0.053)   Data 0.038 (0.037)   Loss 1.5124 (1.7054)   Prec@1 40.625 (36.653)   Prec@5 97.656 (87.628)   [2021-11-17 14:08:36]
  **Train** Prec@1 45.178 Prec@5 90.932 Error@1 54.822
  **Test** Prec@1 55.520 Prec@5 94.930 Error@1 44.480
  **Test** Prec@1 55.520 Prec@5 94.930 Error@1 44.480

==>>[2021-11-17 14:08:52] [Epoch=001/200] [Need: 01:24:43] [learning_rate=0.1000] [Best : Accuracy=55.52, Error=44.48]
  Epoch: [001][000/391]   Time 0.056 (0.056)   Data 0.039 (0.039)   Loss 1.2533 (1.2533)   Prec@1 59.375 (59.375)   Prec@5 94.531 (94.531)   [2021-11-17 14:08:52]
  Epoch: [001][200/391]   Time 0.055 (0.051)   Data 0.039 (0.036)   Loss 1.0923 (1.0760)   Prec@1 61.719 (61.513)   Prec@5 96.094 (96.121)   [2021-11-17 14:09:02]
  **Train** Prec@1 63.816 Prec@5 96.576 Error@1 36.184
  **Test** Prec@1 61.960 Prec@5 96.390 Error@1 38.040
  **Test** Prec@1 61.960 Prec@5 96.390 Error@1 38.040

==>>[2021-11-17 14:09:18] [Epoch=002/200] [Need: 01:25:51] [learning_rate=0.1000] [Best : Accuracy=61.96, Error=38.04]
  Epoch: [002][000/391]   Time 0.056 (0.056)   Data 0.039 (0.039)   Loss 0.8974 (0.8974)   Prec@1 64.844 (64.844)   Prec@5 100.000 (100.000)   [2021-11-17 14:09:18]
  Epoch: [002][200/391]   Time 0.055 (0.053)   Data 0.038 (0.038)   Loss 0.9288 (0.8721)   Prec@1 65.625 (69.084)   Prec@5 95.312 (97.629)   [2021-11-17 14:09:29]
  **Train** Prec@1 69.920 Prec@5 97.672 Error@1 30.080
  **Test** Prec@1 48.400 Prec@5 92.260 Error@1 51.600
  **Test** Prec@1 48.400 Prec@5 92.260 Error@1 51.600

==>>[2021-11-17 14:09:44] [Epoch=003/200] [Need: 01:25:43] [learning_rate=0.1000] [Best : Accuracy=61.96, Error=38.04]
  Epoch: [003][000/391]   Time 0.056 (0.056)   Data 0.039 (0.039)   Loss 0.7688 (0.7688)   Prec@1 72.656 (72.656)   Prec@5 100.000 (100.000)   [2021-11-17 14:09:44]
  Epoch: [003][200/391]   Time 0.052 (0.053)   Data 0.037 (0.037)   Loss 0.6608 (0.7878)   Prec@1 75.781 (72.474)   Prec@5 99.219 (98.037)   [2021-11-17 14:09:55]
  **Train** Prec@1 73.194 Prec@5 98.144 Error@1 26.806
  **Test** Prec@1 67.780 Prec@5 97.300 Error@1 32.220
  **Test** Prec@1 67.780 Prec@5 97.300 Error@1 32.220

==>>[2021-11-17 14:10:11] [Epoch=004/200] [Need: 01:25:23] [learning_rate=0.1000] [Best : Accuracy=67.78, Error=32.22]
  Epoch: [004][000/391]   Time 0.052 (0.052)   Data 0.036 (0.036)   Loss 0.6701 (0.6701)   Prec@1 77.344 (77.344)   Prec@5 96.875 (96.875)   [2021-11-17 14:10:11]
  Epoch: [004][200/391]   Time 0.050 (0.051)   Data 0.034 (0.036)   Loss 0.6418 (0.7227)   Prec@1 77.344 (74.977)   Prec@5 99.219 (98.395)   [2021-11-17 14:10:21]
